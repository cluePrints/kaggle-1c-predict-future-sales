# AUTOGENERATED! DO NOT EDIT! File to edit: 030_cv.ipynb (unless otherwise specified).

__all__ = ['target_forecast_start', 'forecast_length_days', 'sample_all_time', 'sample_no_future', 'train_all_time',
           'train_no_future', 'train_all_time', 'test', 'cross_join', 'november_days', 'test_dates', 'extract_features',
           'single_fold', 'ts_cv', 'FeatureExtractor', 'scaler', 'Pipeline']

# Cell
import pandas as pd
import numpy as np
from datetime import timedelta

# Cell
target_forecast_start = pd.to_datetime('2015-11-01')
forecast_length_days = 30

# Cell
from .trivial_predict import read_train, forecast_last_average, forecast_to_submission

sample_all_time = read_train(n_sample_items=131, sample_random_state=42)

# Cell
sample_no_future = sample_all_time.loc[sample_all_time['date'] < target_forecast_start]

# Cell
train_all_time = read_train()
train_no_future  = train_all_time.loc[train_all_time['date'] < target_forecast_start]
train_all_time = None

test = pd.read_csv('raw/test.csv')

# Cell
november_days = [target_forecast_start + timedelta(days=i) for i in range(0, 30)]

def cross_join(left, right):
    left['_tmp_col'] = 0
    right['_tmp_col'] = 0
    return left.merge(right, on='_tmp_col').drop(['_tmp_col'], axis=1)

test_dates = cross_join(test, pd.DataFrame({'date': november_days}))

# Cell
import pandas as pd

# TODO: add item_id back
def extract_features(sample_all_time, extraction_target, categorical_cols=['shop_id']):
    from sklearn.preprocessing import OneHotEncoder
    from scipy import sparse

    onehot_encoder = OneHotEncoder(handle_unknown='ignore')
    onehot_encoder.fit(sample_all_time[categorical_cols])
    categorical_features = onehot_encoder.transform(extraction_target[categorical_cols])
    days_since = (extraction_target['date']-pd.to_datetime('2012-01-01')).dt.days
    days_since = days_since.to_numpy()[:,np.newaxis]
    continuous_features = [days_since]
    # Note to self: np would complain about sparse matrix being onedimensional :/
    transformed_features = sparse.hstack([categorical_features] + continuous_features)

    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler(with_mean=False)

    # Otherwise it's in COO and doesn't support indexing :/
    # Note to self: adding a new feature hurt SGD convergence which I initially misdiagnosed for sparse matrix mgmt issues
    transformed_features = transformed_features.tocsr()
    transformed_features = scaler.fit_transform(transformed_features)

    return transformed_features

def single_fold(regressor,
                transformed_features,
                dates_frame,
                ids_frame,
                target_frame, target_col,
                forecast_start,
                forecast_length_days):
    # split
    forecast_end_date = forecast_start + timedelta(days = forecast_length_days)
    train_indexes = dates_frame['date'] < forecast_start
    test_indexes = (dates_frame['date'] >= forecast_start) & (dates_frame['date'] <= forecast_end_date)

    grouper = ids_frame['item_id']*100 + ids_frame['shop_id']
    forecast_target_mo = (target_frame
        .groupby(grouper, as_index=False)
        .agg({target_col: 'sum'})
        .rename({target_col: 'item_cnt_month'}, axis=1)
    )

    train_features = transformed_features[train_indexes]
    test_features = transformed_features[test_indexes]

    regressor.fit(train_features, target_frame[train_indexes].squeeze())
    predicted_daily = (regressor
                       .predict(test_features)
                       .squeeze()
                      )
    predicted_daily = pd.DataFrame({'item_id': ids_frame[test_indexes]['item_id'],
                                    'shop_id': ids_frame[test_indexes]['shop_id'],
                                    target_col: predicted_daily})
    predicted_mo = (predicted_daily.groupby(
            ['item_id', 'shop_id'], as_index=False)
            .agg({target_col: 'sum'})
            .rename({target_col: 'item_cnt_month'}, axis=1)
    )

    # TODO: should be part of what's predicted by the func? (so e.g. test targets are transformed)
    predicted_mo['item_cnt_month'] = predicted_mo['item_cnt_month'].clip(0, 20)
    forecast_target_mo['item_cnt_month'] = forecast_target_mo['item_cnt_month'].clip(0, 20)
    from sklearn.metrics import mean_squared_error
    predicted_mo['item_cnt_month_target'] = forecast_target_mo['item_cnt_month']
    rmse = mean_squared_error(predicted_mo['item_cnt_month_target'], predicted_mo['item_cnt_month'])

    return rmse, predicted_mo

# Cell
from sklearn.base import clone
def ts_cv(
    orig_regressor,
    train_all_time, target_col,
    transformed_features,
    n_folds,
    forecast_length_days=30,
    target_forecast_start = pd.to_datetime('2015-11-01')
):
    id_cols = ['item_id', 'shop_id']
    dates_frame = train_all_time[['date']]
    target_frame = train_all_time[['item_cnt_day']]
    ids_frame = train_all_time[id_cols]

    target_forecast_start = pd.to_datetime('2015-11-01')
    forecast_length_days = 30

    fold_rmses = []
    fold_forecast_starts = []
    n_folds = 3
    fold_shift_days = 40
    for delta in range(1, 1+n_folds):
        forecast_start = target_forecast_start - timedelta(days=delta*fold_shift_days)
        rmse, predicted_mo = single_fold(clone(orig_regressor), transformed_features,
               dates_frame, ids_frame, target_frame, target_col,
               forecast_start=forecast_start,
               forecast_length_days=30)
        fold_rmses.append(rmse)
        fold_forecast_starts.append(forecast_start)

    return fold_rmses, fold_forecast_starts

# Cell
from sklearn.preprocessing import OneHotEncoder
from scipy import sparse
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler(with_mean=False)

class FeatureExtractor():
    def __init__(self, categorical_cols=['shop_id']):
        self.onehot_encoder = OneHotEncoder(handle_unknown='ignore')
        self.categorical_cols = categorical_cols

    def fit(self, sample_all_time):
        derived = self._ensure_derived(sample_all_time)
        self.onehot_encoder.fit(derived[self.categorical_cols])

    def _ensure_derived(self, data):
        for categorical_name in self.categorical_cols:
            if ':' in categorical_name:
                split_char_idx = categorical_name.index(':')
                raw_col_name = categorical_name[:split_char_idx]
                derived_col_name = categorical_name[split_char_idx+1:]
                data[categorical_name] = getattr(data[raw_col_name].dt, derived_col_name)

        return data

    def transform(self, extraction_target):
        derived = self._ensure_derived(extraction_target)
        categorical_features = self.onehot_encoder.transform(derived[self.categorical_cols])
        days_since = (extraction_target['date']-pd.to_datetime('2012-01-01')).dt.days
        days_since = days_since.to_numpy()[:,np.newaxis]
        continuous_features = [days_since]
        # Note to self: np would complain about sparse matrix being onedimensional :/
        transformed_features = sparse.hstack([categorical_features] + continuous_features)
        # Otherwise it's in COO and doesn't support indexing :/
        # Note to self: adding a new feature hurt SGD convergence which I initially misdiagnosed for sparse matrix mgmt issues
        transformed_features = transformed_features.tocsr()
        transformed_features = scaler.fit_transform(transformed_features)
        return transformed_features

# Cell
class Pipeline():
    def __init__(self, regressor, feature_extractor,
                 daily_train,
                 daily_test,
                 target_forecast_start=pd.to_datetime('2015-11-01')):
        self.regressor = regressor
        self.feature_extractor = feature_extractor
        self.target_col = 'item_cnt_day'
        count_after = len(daily_train.query('date >= @target_forecast_start'))
        if count_after > 0:
            raise ValueError(f"Expected no entries after target forecast start {target_forecast_start}, got {count_after}")
        self.train_no_future = daily_train
        self.test_dates = daily_test

    def ensure_train_features(self):
        if not hasattr(self, 'transformed_features'):
            self.feature_extractor.fit(self.train_no_future)
            self.transformed_features = self.feature_extractor.transform(self.train_no_future)

    def cv(self, n_folds=3):
        self.ensure_train_features()
        self.cv_fold_rmses, self.cv_fold_forecast_starts = ts_cv(
            self.regressor, self.train_no_future, self.target_col, self.transformed_features, n_folds)
        return sum(self.cv_fold_rmses) / len(self.cv_fold_rmses)

    def fit(self):
        self.ensure_train_features()
        self.test_features = self.feature_extractor.transform(self.test_dates)
        self.regressor.fit(self.transformed_features, self.train_no_future['item_cnt_day'])

    def predict(self):
        predicted_daily = self.regressor.predict(self.test_features)
        self.predicted_daily = pd.DataFrame({'item_id': self.test_dates['item_id'],
                                             'shop_id': self.test_dates['shop_id'],
                                              self.target_col: predicted_daily})
        self.predicted_mo = (self.predicted_daily.groupby(
                ['item_id', 'shop_id'], as_index=False)
                .agg({self.target_col: 'sum'})
                .rename({self.target_col: 'item_cnt_month'}, axis=1)
        )

    def prepare_submit(self, name, force=False):
        predicted_mo = self.predicted_mo.copy()
        predicted_mo['item_cnt_month'] = predicted_mo['item_cnt_month'].clip(0, 20)
        self.submission = forecast_to_submission(predicted_mo)
        path = f'submissions/submission_{name}.csv'
        import os;
        if os.path.isfile(path) and not force:
            raise ValueError(path + ' already exists.')
        self.submission.to_csv(path, index=False)